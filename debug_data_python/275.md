### 问题描述：
<p>为什么无法使用selenium实现翻页爬取？</p>
问题遇到的现象和发生背景
使用selenium库爬取多家公司多页的数据，为什么无法使用selenium实现翻页爬取？
用代码块功能插入代码，请勿粘贴截图

```python

# =============================================================================
# 9.2 东方财富网数据挖掘实战    实战2 第二题
# =============================================================================


from selenium import webdriver
import re


def dongfang(company, num):
    browser = webdriver.Chrome()  # 这里改成了有界面模式，方便调试代码
    url = 'http://so.eastmoney.com/news/s?keyword=' + company
    browser.get(url)
    browser.find_element("xpath",'//*[@id="kw"]').send_keys('str(num)')
    browser.find_element("xpath",'//*[@id="kw"]').send_keys(Keys.ENTER)
    data = browser.page_source
    browser.quit()
    # print(data)  # 如果正则发生变化，可以通过打印源代码进行调试
    
    p_title = '(.*?)'
    p_href = '(.*?)'
    p_date = '(.*?) - '
    title = re.findall(p_title, data)
    href = re.findall(p_href, data)
    date = re.findall(p_date, data, re.S)

    for i in range(len(title)):
        title[i] = re.sub('<.*?>', '', title[i])
        date[i] = date[i].split(' ')[0]
        print(str(i+1) + '.' + title[i] + ' - '+ date[i])
        print(href[i])





companys = ['阿里巴巴', '万科集团', '百度集团', '腾讯', '京东']
for company in companys:
    for i in range(3):  # 这里一共爬取了3页
        dongfang(company, i+1)  # i是从0开始的序号，所以要写成i+1表示第几页
        print("第" + str(i+1) + "页" + company + '东方财富网爬取成功')  # i是从0开始的序号，所以写i+1
        time.sleep(3)  # 不要爬太快，爬太快会被百度反爬

运行结果及报错内容

我的解答思路和尝试过的方法
无
我想要达到的结果
可能是关于翻页的两行代码不正确，希望得到正确的代码
   
```
            收起
             写回答
     好问题
        0 提建议
       追加酬金
       关注问题
      微信扫一扫  点击复制链接  分享  邀请回答
      编辑 收藏 删除   收藏 举报  追加酬金 (90%的用户在追加酬金后获得了解决方案)  当前问题酬金 ¥ 15 
            (您已提供 ¥ 20， 还可追加 ¥
            485)
            支付方式 余额支付  
              余额: ¥ 499 扫码支付     提供问题酬金的用户不参与问题酬金结算和分配 
            支付即为同意
            《付费问题酬金结算规则》 确认追加   结题 再想想 删除 再等等
### 修改方案：
你的Xpath有问题，另外你的页码没有生效，你需要找正确的xpath，你目前是在找input找xpath的方法

```python

from selenium import webdriver
import re
import time

def dongfang(company, num):
    browser = webdriver.Chrome()  # 这里改成了有界面模式，方便调试代码
    url = 'http://so.eastmoney.com/news/s?keyword=' + company
    browser.get(url)
    browser.find_element("xpath",'/html/body/div[1]/div[3]/div[1]/div[5]/div/form/input').send_keys(str(num))
    browser.find_element("xpath",'/html/body/div[1]/div[3]/div[1]/div[5]/div/form/input').send_keys(webdriver.common.keys.Keys.ENTER)
    data = browser.page_source
    browser.quit()
    # print(data)  # 如果正则发生变化，可以通过打印源代码进行调试

    p_title = '<div class="news_item_t"[^>]*><a[^>]*>(.*?)</a>'
    p_href = '<div class="news_item_url"[^>]*><a[^>]*>(.*?)</a></div>'
    p_date = '<div class="news_item_c"><span class="news_item_time">(.*?) - </span>'
    title = re.findall(p_title, data)
    href = re.findall(p_href, data)
    date = re.findall(p_date, data, re.S)

    for i in range(len(title)):
        title[i] = re.sub('<.*?>', '', title[i])
        date[i] = date[i].split(' ')[0]
        print(str(i+1) + '.' + title[i] + ' - '+ date[i])
        print(href[i])





companys = ['阿里巴巴', '万科集团', '百度集团', '腾讯', '京东']
for company in companys:
    for i in range(3):  # 这里一共爬取了3页
        dongfang(company, i+1)  # i是从0开始的序号，所以要写成i+1表示第几页
        print("第" + str(i+1) + "页" + company + '东方财富网爬取成功')  # i是从0开始的序号，所以写i+1
        time.sleep(3)  # 不要爬太快，爬太快会被百度反爬



```

### 人工打分：
